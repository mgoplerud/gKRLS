% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ml_function.R
\name{ml_gKRLS}
\alias{ml_gKRLS}
\alias{SL.mgcv}
\alias{predict.SL.mgcv}
\alias{add_bam_to_mlr3}
\title{Machine Learning with gKRLS}
\usage{
SL.mgcv(Y, X, newX, formula, family, obsWeights, bam = FALSE, ...)

\method{predict}{SL.mgcv}(object, newdata, allow_missing_levels = TRUE, ...)

add_bam_to_mlr3()
}
\arguments{
\item{Y}{The outcome variable.}

\item{X}{All predictors used in the model, including those inside and outside
of the kernel.}

\item{newX}{A new dataset used for prediction; if nothing is provided, the
original data will be used. See the documentation in \code{SuperLearner}
for details.}

\item{formula}{The formula used for \code{mgcv}.}

\item{family}{A string variable passed to \code{SL.mgcv}. See
\code{SuperLearner} documentation for details on valid options.}

\item{obsWeights}{A vector of numeric weights for each observation. See
\code{SuperLearner} documentation for details on valid options.}

\item{bam}{A logical value for whether \code{mgcv::bam} should be used
instead of \code{mgcv::gam}. Default is \code{FALSE}. For large datasets,
this can dramatically improve estimation time. See Wood et al. (2015) for
details on \code{bam}.}

\item{...}{Additional arguments to \code{mgcv::gam} and \code{mgcv::bam}.}

\item{object}{A gKRLS model.}

\item{newdata}{A new dataset uses for prediction. If no data provided, the original
data will be used.}

\item{allow_missing_levels}{A logical variable indicates whether missing levels are
allowed for prediction. The default is True.}
}
\description{
This provides a number of functions to integrate machine
  learning with gKRLS (and more generally \code{mgcv}). Integration into
  \code{SuperLearner} and \code{DoubleML} (via \code{mlr3}) is described
  below. It is often useful to load \code{SuperLearner} before \code{gKRLS}
  or \code{mgcv} to avoid functions including \code{gam} and \code{s} being
  masked from other packages.
}
\details{
\code{SuperLearner} integration is provided by \code{SL.mgcv} and
  the corresponding predict method. `mgcv::bam` can be enabled by using
  \code{bam = TRUE}. Note that a formula must be explicitly provided as a
  \bold{character}, e.g. " ~ X1 + X2".

\code{DoubleML} integration is provided in two ways. First, one could load
\code{mlr3extralearners} to access \code{regr.gam} and \code{classif.gam}.
Second, this package provides \code{mgcv::bam} integration directly with a
slight adaption of the \code{mlr3extralearner} implementation. These can be
either manually added to the list of \code{mlr3} learners by calling
\code{add_bam_to_mlr3()} or direct usage. Examples are provided below. For
\code{classif.bam} and \code{regr.bam}, the formula argument is mandatory.
}
\examples{
set.seed(789)
N <- 100
x1 <- rnorm(N)
x2 <- rbinom(N, size = 1, prob = .2)
y <- x1^3 - 0.5 * x2 + rnorm(N, 0, 1)
y <- y * 10
X <- cbind(x1, x2, x1 + x2 * 3)
X <- cbind(X, "x3" = rexp(nrow(X)))

# Estimate Ensemble with SuperLearner
sl_m <- function(...) {
  SL.mgcv(formula = ~ x1 + x2 + x3, ...)
}
if (requireNamespace("SuperLearner", quietly = TRUE)) {
  require(SuperLearner)
  fit_SL <- SuperLearner::SuperLearner(
    Y = y, X = data.frame(X),
    SL.library = "sl_m"
  )
  pred <- predict(fit_SL, newdata = data.frame(X))
}
# Estimate Double/Debiased Machine Learning
if (requireNamespace("DoubleML", quietly = TRUE)) {
  require(DoubleML)
  # Load the models; for testing *ONLY* have multiplier of 2
  double_bam_1 <- LearnerRegrBam$new()
  double_bam_1$param_set$values$formula <- ~ s(x1, x3, bs = "gKRLS", 
    xt = gKRLS(sketch_multiplier = NULL, sketch_size_raw = 2))
  double_bam_2 <- LearnerClassifBam$new()
  double_bam_2$param_set$values$formula <- ~ s(x1, x3, bs = "gKRLS", 
    xt = gKRLS(sketch_multiplier = NULL, sketch_size_raw = 2))

  # Create data
  dml_data <- DoubleMLData$new(
    data = data.frame(X, y),
    x_cols = c("x1", "x3"), y_col = "y",
    d_cols = "x2"
  )
  # Estimate effects treatment (works for other DoubleML methods)
  dml_est <- DoubleMLIRM$new(
    data = dml_data,
    n_folds = 2,
    ml_g = double_bam_1,
    ml_m = double_bam_2
  )$fit()
}
}
\references{
Wood, Simon N and Goude, Yannig and Simon Shaw. 2015. "Generalized Additive
Models for Large Data Sets." \emph{Journal of the Royal Statistical Society:
Series C (Applied Statistics)} 64(1):139-155.
}
