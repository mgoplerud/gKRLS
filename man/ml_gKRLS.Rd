% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ml_function.R
\name{SL.mgcv}
\alias{SL.mgcv}
\alias{predict.SL.mgcv}
\alias{add_bam_to_mlr3}
\title{Machine Learning with gKRLS}
\usage{
SL.mgcv(Y, X, newX, formula, family, obsWeights, bam = FALSE, ...)

\method{predict}{SL.mgcv}(object, newdata, allow_missing_levels = TRUE, ...)

add_bam_to_mlr3()
}
\arguments{
\item{Y}{Specify the outcome variable.}

\item{X}{All independent variables include variables in and outside the kernel.}

\item{newX}{A new dataset uses for prediction. If no data provided, the original 
data will be used.}

\item{formula}{A gKRLS style formula. See details in the help(gKRLS) and help(gam).}

\item{family}{A string variable indicate the distribution and link function to use. 
The default is gaussian distribution.}

\item{obsWeights}{The weights for observations.}

\item{bam}{A logical variable indicates whether a gKRLS model is applying to a 
very large dataset. The default is False.}

\item{...}{Additional arguments to gam/bam.}

\item{object}{A gKRLS model.}

\item{newdata}{A new dataset uses for prediction. If no data provided, the original 
data will be used.}

\item{allow_missing_levels}{A logical variable indicates whether missing levels are 
allowed for prediction. The default is True.}
}
\description{
This provides a number of functions to integrate machine learning with gKRLS
(and more generally `mgcv`). Integrations into `SuperLearner` and `DoubleML`
(via `mlr3`) are provided below.
}
\details{
SuperLearner integration is provided by `SL.mgcv` and the corresponding
predict method. `mgcv::bam` can be enabled by using `bam = TRUE`. Note that a
formula must be explicitly provided as a *character*, e.g. " ~ X1 + X2".

`DoubleML` integration is provided in two ways. First, one could load
`mlr3extralearners` to access `regr.gam` and `classif.gam`. Second, this
package provides `mgcv::bam` integration directly with a slight adaption of
the `mlr3extralearner` implementation. These can be either manually added to
the list of `mlr3` learners by calling `add_bam_to_mlr3()` or direct usage.
Examples are provided below. For `classif.bam` and `regr.bam`, the formula
argument is mandatory.
}
\examples{
library(gKRLS)
library(DoubleML)
library(glue)
library(tidyverse)

n <- 5000
treatment <- sample(c(0,1), n, replace = T)
x2 <- rnorm(n)
x3 <- rnorm(n)
state <- sample(letters, n, replace = T)
y = 0.3*treatment + 0.4*x2 +0.5*x3 + rnorm(n)
data <- data.frame(y,treatment, x2, x3, state)
data$state <- as.character(data$state)

# Double machine learning intergration

data_dml <- cbind(data,  model.matrix(~ state, data)[, -1]) \%>\%
 select(-state) \%>\% as.data.frame()
 
gkrls_formul <- as.formula(glue("~ {{paste(grep(colnames(data_dml), pattern='state', value = T), collapse = '+')}} + 
                                s( x2,x3, bs = 'gKRLS')", .open = '{{', .close = '}}'))
                                
ml_g <- LearnerRegrBam$new()
ml_g$param_set$values$formula <- update.formula(gkrls_formul, as.character(glue('y ~ .')))
ml_m <- LearnerRegrBam$new()
ml_m$param_set$values$formula <- update.formula(gkrls_formul, as.character(glue('treatment ~ .')))

ml_g$param_set$values$method <- 'REML'
ml_m$param_set$values$method <- 'REML'

data_DML <- double_ml_data_from_data_frame(
 df = data_dml,
 y_col = "y",
 d_cols = 'treatment',
 x_cols = setdiff(names(data_dml), c("y", 'treatment'))
) 

## Fit Partial Linear Regression
dml_plr <- DoubleMLPLR$new(data_DML, ml_g, ml_m)
dml_plr$fit()
dml_plr

## Fit ATE
### change treatment formula to classification class.

ml_m1 <- LearnerClassifBam$new()
ml_m1$param_set$values$formula <- update.formula(gkrls_formul, as.character(glue('treatment ~ .')))

dml_ATE <- DoubleMLIRM$new(data_DML, ml_g, ml_m1, 
                          score = 'ATE')
dml_ATE$fit()
dml_ATE

# Super learner intergration

library(SuperLearner) # need to pre-install and load this package 

data$state <- as.factor(data$state)

gkrls_sl <- function(...){SL.mgcv(..., bam = TRUE, formula = "~ state + s(treatment, 
                                                         x2, x3, bs = 'gKRLS')")}
                                                         
fit_sl <- SuperLearner(Y = data$y, 
                      X = data, family = 'gaussian',
                      SL.library = 'gkrls_sl',
                      verbose = T)
                      
pred <- predict(fit_sl, newdata = data)
}
